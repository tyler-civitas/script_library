#!/bin/bash
export PYSPARK_DRIVER_PYTHON=jupyter
export PYSPARK_DRIVER_PYTHON_OPTS="notebook --NotebookApp.open_browser=True --NotebookApp.ip='localhost' --NotebookApp.port=8888"

#Note: If you are installing Spark on a Virtual Machine and
#would like to access jupyter from your host browser, you
#should set the NotebookApp.ip flag to --NotebookApp.ip='0.0.0.0'
#so that your VM's jupyter server will accept external connections.
# You can then access jupyter notebook from the host
# machine on port 8888.



${SPARK_HOME}/bin/pyspark \
--master local[4] \
--executor-memory 1G \
--driver-memory 1G \
--conf spark.sql.warehouse.dir="file:///tmp/spark-warehouse" \
--packages com.databricks:spark-csv_2.11:1.5.0 \
--packages com.amazonaws:aws-java-sdk-pom:1.10.34 \
--packages org.apache.hadoop:hadoop-aws:2.7.3

# Details on application parameters
# http://spark.apache.org/docs/latest/submitting-applications.html

# TO RUN

#import pyspark as ps

# spark = ps.sql.SparkSession.builder.getOrCreate()
